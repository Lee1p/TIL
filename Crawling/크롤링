
크롤링(Crawling) or 스크래핑(Scraping)
- 특정 웹 사이트의 페이지를 탐색해서 내가 원하는 정보를 수집하는 행동
- 웹 페이지의 데이터를 긁어오기

다른 웹 사이트의 데이터를 가져오고 싶다면..
1. 상대방(웹사이트)이 나에게 DB 권한을 준다면.. > 가장 이상적인 방법 > 불가능!!
2. 상대방이 외부에 OpenAPI 공개 > 제한적 + 무난한 방법~
3. 웹 페이지의 소스를 긁어서 직접 원하는 데이터를 추출 > 크롤링


크롤링 주의점!!
- 허가 문제, 저작권 문제
- 정도껏~ > 긁어오는 작업 > 프로그램 > 속도 빠름 && 무제한 > 서버 입장 > 서버 비용 & 트래픽 증가
- 크롤링 금지 사이트 > Cloudflare or reCAPCHA
 
JSoup을 사용한 웹 크롤링

1.JSoup은 HTML을 파싱하고 데이터를 추출할 수 있는 자바 라이브러리

Jsoup.connect(url).get(): 웹 페이지를 가져오는 메소드.
doc.select("selector"): CSS 선택자를 사용하여 원하는 요소를 찾는 메소드.
element.attr(attribute): 요소의 속성 값을 가져오는 메소드.
element.text(): 요소의 텍스트 값을 가져오는 메소드.

2. Selenium을 사용한 웹 크롤링

Selenium은 브라우저 자동화 도구로, 동적인 웹 페이지에서 데이터를 추출할 때 유용합니다. 
CSR(클라이언트 사이드 렌더링) 방식으로 페이지가 로드되는 경우, 
즉 JavaScript로 동적으로 생성되는 페이지에서는 Selenium이 필요합니다.

driver.get(url): 주어진 URL로 이동.
driver.findElement(By.selector): 주어진 선택자로 요소를 찾음.
element.getText(): 요소의 텍스트를 가져옴.
element.getAttribute("attribute"): 요소의 속성 값을 가져옴.

3. 크롤링의 기본 단계 

목표 페이지 분석: 크롤링하려는 웹 페이지가 동적/정적인지 확인하고, 어떤 데이터를 추출할지 결정합니다.
웹 페이지 로드: 원하는 웹 페이지를 HttpURLConnection (정적 페이지) 또는 Selenium (동적 페이지)을 사용하여 로드합니다.
데이터 추출: 필요한 데이터를 추출합니다. 일반적으로 HTML 요소의 텍스트, 속성, 태그 등을 추출합니다.
데이터 저장: 크롤링한 데이터를 CSV, Excel, 데이터베이스 등으로 저장합니다.


JSoup은 간단한 HTML 페이지에서 정보를 추출할 때 매우 유용하며 빠릅니다.
Selenium은 동적인 웹사이트에서 데이터가 JavaScript로 렌더링되는 경우 매우 효과적입니다.
